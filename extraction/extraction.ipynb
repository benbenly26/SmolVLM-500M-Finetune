{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3eafa18",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "%pip install -q accelerate datasets peft tensorboard\n",
    "%pip install  -U -q transformers trl datasets peft accelerate\n",
    "%pip install -q flash-attn --no-build-isolation\n",
    "%pip install pillow\n",
    "%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e4d3e4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "%pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f56cc19",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import tqdm\n",
    "\n",
    "from peft import PeftModel\n",
    "from transformers import AutoProcessor, Idefics3ForConditionalGeneration\n",
    "\n",
    "model_id = \"HuggingFaceTB/SmolVLM-500M-Instruct\" # Load the model here\n",
    "adapter_save_path = \"\"   # Load the adapter here from the trained model\n",
    "\n",
    "try:\n",
    "    processor = AutoProcessor.from_pretrained(model_id)\n",
    "    \n",
    "    # Load the base model (disable flash_attn if ROCm has issues)\n",
    "    base_model = Idefics3ForConditionalGeneration.from_pretrained(\n",
    "        model_id,  \n",
    "        torch_dtype=torch.bfloat16,\n",
    "        _attn_implementation=\"flash_attention_2\" if torch.cuda.is_available() else None,  # comment this if ROCm\n",
    "        device_map=\"auto\"\n",
    "    )\n",
    "    \n",
    "    # Load the adapter\n",
    "    trained_model = PeftModel.from_pretrained(\n",
    "        base_model, \n",
    "        adapter_save_path,\n",
    "        device_map=\"auto\"\n",
    "    )\n",
    "    \n",
    "    print(\"Model & adapter loaded successfully!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error loading model: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9711c47a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "%pip install pymupdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42d43dd",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import fitz\n",
    "from PIL import Image\n",
    "\n",
    "pdf_path = \"/home/test.pdf\"  # Replace with your PDF path\n",
    "output_dir = \"/home/output_images/\"  # Directory to save images\n",
    "output_text_dir = \"/home/Folder/\"  # Directory to save markdown files\n",
    "\n",
    "# Create output directories if they don't exist\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "os.makedirs(output_text_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "# Convert PDF pages to images\n",
    "doc = fitz.open(pdf_path)\n",
    "image_paths = []\n",
    "for i, page in enumerate(doc):\n",
    "    pix = page.get_pixmap()\n",
    "    img_path = os.path.join(output_dir, f\"page_{i+1}.png\")\n",
    "    image = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "    image.save(img_path)\n",
    "    image_paths.append(img_path)\n",
    "\n",
    "import os\n",
    "DEVICE=\"cuda\"\n",
    "\n",
    "# Process each image with the quantized model\n",
    "for page_num, img_path in enumerate(image_paths, start=1):\n",
    "    image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"Extract all the text from the image\"\n",
    "},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"image\"},\n",
    "                {\"type\": \"text\", \"text\": \"Extract all the text from the image\"}\n",
    "            ]\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    prompt = processor.apply_chat_template(messages, add_generation_prompt=True)\n",
    "\n",
    "    inputs = processor(images=image, text=prompt, return_tensors=\"pt\").to(DEVICE)\n",
    "   \n",
    "    with torch.no_grad():\n",
    "        output_ids = trained_model.generate(**inputs, max_new_tokens=2000)\n",
    "        extracted_text = processor.batch_decode(output_ids, skip_special_tokens=True)[0]\n",
    "\n",
    "    # Remove the prompt from the extracted text\n",
    "    # Assuming the prompt ends with a specific marker or can be identified by a pattern\n",
    "    # Here, we assume the prompt ends with \"Maintain original structure and formatting as closely as possible.\"\n",
    "    prompt_end_marker = \"Maintain original structure and formatting as closely as possible.\"\n",
    "    prompt_end_index = extracted_text.find(prompt_end_marker)\n",
    "    \n",
    "    if prompt_end_index != -1:\n",
    "        extracted_text_only = extracted_text[prompt_end_index + len(prompt_end_marker):].strip()\n",
    "    else:\n",
    "        extracted_text_only = extracted_text.strip()\n",
    "\n",
    "    md_file_path = os.path.join(output_text_dir, f\"page_{page_num}.md\")\n",
    "    with open(md_file_path, \"w\") as md_file:\n",
    "        md_file.write(f\"# Page {page_num}\\n\\n\")\n",
    "        md_file.write(extracted_text_only)\n",
    "\n",
    "    print(f\"Saved extracted text from page {page_num} to {md_file_path}\")\n",
    "\n",
    "print(f\"Text extraction completed. Markdown files saved in {output_text_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3be363d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "%pip install markdown pdfkit\n",
    "%pip install pypandoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d903777",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pypandoc\n",
    "\n",
    "# Replace with your folder\n",
    "md_folder = r'/home/Folder/'\n",
    "output_pdf = '/home/New.pdf'\n",
    "\n",
    "# Get all .md files\n",
    "md_files = [\n",
    "    os.path.join(md_folder, f)\n",
    "    for f in os.listdir(md_folder)\n",
    "    if f.endswith('.md')\n",
    "]\n",
    "\n",
    "# Sort files based on the number in \"page_XX\"\n",
    "md_files.sort(key=lambda x: int(re.search(r'page_(\\d+)', x).group(1)))\n",
    "\n",
    "# Combine all markdown files into one string\n",
    "combined_md = ''\n",
    "for file_path in md_files:\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        combined_md += f.read() + '\\n\\n\\\\newpage\\n\\n'  # page break between files\n",
    "\n",
    "# Convert to PDF using Pandoc\n",
    "pypandoc.convert_text(\n",
    "    combined_md,\n",
    "    'pdf',\n",
    "    format='md',\n",
    "    outputfile=output_pdf,\n",
    "    extra_args=['--pdf-engine=wkhtmltopdf']\n",
    ")\n",
    "\n",
    "print(\" PDF created successfully:\", output_pdf)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
